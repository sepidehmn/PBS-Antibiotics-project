{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8cceda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PBS antibiotics (2015) + ABS ERP — my simple end-to-end script\n",
    "# What I’m doing:\n",
    "# 1) Clean the two raw CSVs (ABS population + PBS).\n",
    "# 2) Compute scripts per 1,000 people (using ABS ERP for 2015).\n",
    "# 3) Make 3 plots: (a) monthly average, (b) top 5 classes, (c) cumulative.\n",
    "\n",
    "from pathlib import Path\n",
    "import re\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# ---------- 0) Paths (I set this to where my raw files are) ----------\n",
    "DATA_DIR = Path(\"/Users/sepidehmianji/Personal data projects for Linkedin/Project 1/pbs_antibiotics_project/data/raw\")\n",
    "ABS_IN = DATA_DIR / \"population_sample.csv\"\n",
    "PBS_IN = DATA_DIR / \"pbs-atc-2015.csv\"\n",
    "\n",
    "OUT_DIR = DATA_DIR / \"cleaned\"; OUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "FIG_DIR = DATA_DIR / \"figures\"; FIG_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# ---------- small helpers I reuse ----------\n",
    "def parse_month(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"I try several common date formats for month labels.\"\"\"\n",
    "    s = series.astype(str).str.strip()\n",
    "    p = pd.to_datetime(s, format=\"%b-%Y\", errors=\"coerce\")       # e.g., Dec-2015\n",
    "    if p.notna().sum() == 0:\n",
    "        p = pd.to_datetime(s, format=\"%B %Y\", errors=\"coerce\")   # e.g., December 2015\n",
    "    if p.notna().sum() == 0:\n",
    "        p = pd.to_datetime(s, errors=\"coerce\")                   # fallback (YYYY-MM, etc.)\n",
    "    return p\n",
    "\n",
    "def to_number(x):\n",
    "    \"\"\"Turn strings like '12,345' into numbers, else NaN.\"\"\"\n",
    "    return pd.to_numeric(str(x).replace(\",\", \"\"), errors=\"coerce\")\n",
    "\n",
    "# =========================\n",
    "# 1) Clean ABS population\n",
    "# =========================\n",
    "# The ABS CSV has multiple header bands + odd delimiters, so I let pandas sniff the delimiter.\n",
    "abs_raw = pd.read_csv(ABS_IN, sep=None, engine=\"python\", header=None,\n",
    "                      encoding=\"latin1\", on_bad_lines=\"skip\")\n",
    "\n",
    "# I find a cell that labels the month column (e.g., 'Collection Month' or 'Month').\n",
    "month_pos = None\n",
    "for i in range(min(250, len(abs_raw))):\n",
    "    for j in range(min(100, abs_raw.shape[1])):\n",
    "        cell = str(abs_raw.iat[i, j]).strip().lower()\n",
    "        if cell.startswith(\"collection month\") or cell == \"month\":\n",
    "            month_pos = (i, j); break\n",
    "    if month_pos: break\n",
    "if not month_pos:\n",
    "    raise SystemExit(\"ABS: couldn't find a 'Collection Month'/'Month' label in the file.\")\n",
    "\n",
    "mrow, mcol = month_pos\n",
    "\n",
    "# I look for a nearby header row that mentions 'Estimated Resident Population' and 'Australia'.\n",
    "erp_row = None\n",
    "for i in range(max(0, mrow-60), min(abs_raw.shape[0], mrow+80)):\n",
    "    text = \" | \".join(abs_raw.iloc[i].astype(str)).lower()\n",
    "    if (\"estimated resident population\" in text) and (\"australia\" in text):\n",
    "        erp_row = i; break\n",
    "if erp_row is None:\n",
    "    raise SystemExit(\"ABS: couldn't find a header row for 'Estimated Resident Population' (Australia).\")\n",
    "\n",
    "# From the month column, I find where the real monthly data starts (first parseable date).\n",
    "parsed_months = parse_month(abs_raw.iloc[mrow+1:, mcol])\n",
    "if parsed_months.notna().sum() == 0:\n",
    "    raise SystemExit(\"ABS: month values under the label aren’t parseable. Please open the CSV and check.\")\n",
    "data_start = parsed_months.dropna().index[0]\n",
    "\n",
    "# I figure out which column contains the Australia ERP series by scanning the header band.\n",
    "erp_col_idx = None\n",
    "for j in range(abs_raw.shape[1]):\n",
    "    col_text = \" | \".join(abs_raw.iloc[erp_row:erp_row+3, j].astype(str)).lower()\n",
    "    if (\"estimated resident population\" in col_text) and (\"australia\" in col_text):\n",
    "        erp_col_idx = j; break\n",
    "if erp_col_idx is None:\n",
    "    raise SystemExit(\"ABS: couldn’t identify the ERP Australia column.\")\n",
    "\n",
    "# I build a tidy ABS dataframe with Month + ERP_Australia.\n",
    "abs_months = parse_month(abs_raw.iloc[data_start:, mcol])\n",
    "abs_erp = abs_raw.iloc[data_start:, erp_col_idx].map(to_number)\n",
    "abs_clean = pd.DataFrame({\"Month\": abs_months, \"ERP_Australia\": abs_erp}).dropna().reset_index(drop=True)\n",
    "abs_clean.to_csv(OUT_DIR / \"population_clean.csv\", index=False)\n",
    "\n",
    "# I take the last available ERP value in 2015 (often December). If ABS reported in thousands, I scale up.\n",
    "erp_2015 = abs_clean.loc[abs_clean[\"Month\"].dt.year == 2015, \"ERP_Australia\"].iloc[-1]\n",
    "if erp_2015 < 1_000_000:   # e.g., 23,940 means 23,940,000\n",
    "    erp_2015 *= 1_000\n",
    "\n",
    "# ======================\n",
    "# 2) Clean PBS (2015)\n",
    "# ======================\n",
    "# PBS files come in a couple of schemas, so I handle both.\n",
    "try:\n",
    "    pbs_raw = pd.read_csv(PBS_IN, encoding=\"latin1\")\n",
    "except Exception:\n",
    "    pbs_raw = pd.read_csv(PBS_IN, sep=None, engine=\"python\", encoding=\"latin1\", on_bad_lines=\"skip\")\n",
    "\n",
    "cols = set(pbs_raw.columns)\n",
    "\n",
    "# I pick a services column robustly (Services / Number of services / Scripts).\n",
    "svc_candidates = [c for c in pbs_raw.columns if c.lower().strip() in {\"services\", \"number of services\", \"scripts\"}]\n",
    "if not svc_candidates:\n",
    "    svc_candidates = [c for c in pbs_raw.columns if (\"service\" in c.lower()) or (\"script\" in c.lower())]\n",
    "if not svc_candidates:\n",
    "    raise SystemExit(\"PBS: couldn't find a 'Services' column.\")\n",
    "\n",
    "svc_col = svc_candidates[0]\n",
    "\n",
    "# I build a real datetime month.\n",
    "if {\"Year\", \"Month\"} <= cols:\n",
    "    m = pbs_raw[\"Month\"].astype(str).str.strip()\n",
    "    y = pbs_raw[\"Year\"].astype(str).str.strip()\n",
    "    dt = pd.to_datetime(m + \"-\" + y, format=\"%B-%Y\", errors=\"coerce\")\n",
    "    if dt.notna().sum() == 0:\n",
    "        dt = pd.to_datetime(m + \"-\" + y, format=\"%b-%Y\", errors=\"coerce\")\n",
    "    if dt.notna().sum() == 0:\n",
    "        # If month is numeric\n",
    "        dt = pd.to_datetime(dict(year=pd.to_numeric(y, errors=\"coerce\"),\n",
    "                                 month=pd.to_numeric(m, errors=\"coerce\"),\n",
    "                                 day=1), errors=\"coerce\")\n",
    "else:\n",
    "    dt = pd.to_datetime(pbs_raw[\"Month\"], errors=\"coerce\")\n",
    "\n",
    "df = pbs_raw.copy()\n",
    "df[\"Month_dt\"] = dt\n",
    "df[svc_col] = pd.to_numeric(df[svc_col], errors=\"coerce\")\n",
    "df = df.dropna(subset=[\"Month_dt\", svc_col])\n",
    "\n",
    "# I try to get the ATC code and class name.\n",
    "if \"ATC Code\" in df.columns:\n",
    "    df[\"atc_code\"] = df[\"ATC Code\"].astype(str)\n",
    "    df[\"class_name\"] = df.get(\"ATC Level 4 Name\", \"Unknown\").astype(str)\n",
    "elif \"ATC_Classification\" in df.columns:\n",
    "    text = df[\"ATC_Classification\"].astype(str)\n",
    "    # capture J01… anywhere (also handles 'J 01' or '(J01AA)')\n",
    "    df[\"atc_code\"] = text.str.extract(r'(?i)\\b(J\\s*0*1[A-Z0-9]{0,3})\\b', expand=False)\n",
    "    df[\"atc_code\"] = df[\"atc_code\"].str.replace(r\"\\s+\", \"\", regex=True).str.upper()\n",
    "    # class name = text without a leading code + dash/colon, if present\n",
    "    df[\"class_name\"] = text.str.replace(r'(?i)^\\s*J\\s*0*1[A-Z0-9]{0,3}\\s*[-–:]\\s*', '', regex=True)\n",
    "else:\n",
    "    # If I can’t find any ATC columns, I still keep going but label them as unknown.\n",
    "    df[\"atc_code\"] = \"NA\"\n",
    "    df[\"class_name\"] = \"Unknown\"\n",
    "\n",
    "# I keep antibiotics if I can detect them (J01 or class name containing 'antibacter/antibiot').\n",
    "abx_mask = (\n",
    "    df[\"atc_code\"].astype(str).str.replace(r\"\\s+\", \"\", regex=True).str.upper().str.startswith(\"J01\")\n",
    "    | df[\"class_name\"].str.contains(\"antibacter\", case=False, na=False)\n",
    "    | df[\"class_name\"].str.contains(\"antibiot\",   case=False, na=False)\n",
    ")\n",
    "df_abx = df[abx_mask].copy()\n",
    "\n",
    "# I only keep 2015.\n",
    "df_abx = df_abx[df_abx[\"Month_dt\"].dt.year == 2015]\n",
    "\n",
    "# If nothing matched antibiotics, I fall back to ALL PBS rows in 2015 (so I still get figures).\n",
    "use_df = df_abx if len(df_abx) > 0 else df[df[\"Month_dt\"].dt.year == 2015].copy()\n",
    "if len(df_abx) == 0:\n",
    "    print(\"[Note] Couldn’t confidently detect antibiotics (J01). Falling back to all PBS rows in 2015 for charts.\")\n",
    "\n",
    "# I build a clean table for plotting.\n",
    "pbs = pd.DataFrame({\n",
    "    \"rx_month\":  use_df[\"Month_dt\"].dt.to_period(\"M\").astype(str),\n",
    "    \"class_name\": use_df[\"class_name\"].astype(str),\n",
    "    \"scripts\":   use_df[svc_col].fillna(0).astype(\"float64\")\n",
    "})\n",
    "\n",
    "# Per-capita (scripts per 1,000 people)\n",
    "pbs[\"scripts_per_1000\"] = pbs[\"scripts\"] / (erp_2015 / 1_000.0)\n",
    "pbs[\"rx_month_dt\"] = pd.to_datetime(pbs[\"rx_month\"], errors=\"coerce\")\n",
    "pbs = pbs.dropna(subset=[\"rx_month_dt\"]).copy()\n",
    "\n",
    "# =========================\n",
    "# 3) Visualisations I want\n",
    "# =========================\n",
    "\n",
    "# (a) Average Antibiotic Scripts per 1,000 People by Month (2015)\n",
    "monthly_rate = (\n",
    "    pbs.sort_values(\"rx_month_dt\")\n",
    "       .groupby(pbs[\"rx_month_dt\"].dt.to_period(\"M\"))[\"scripts_per_1000\"]\n",
    "       .sum()\n",
    ")\n",
    "plt.figure()\n",
    "monthly_rate.plot(marker=\"o\")\n",
    "plt.title(\"Average Antibiotic Scripts per 1,000 People by Month (2015)\")\n",
    "plt.xlabel(\"Month\"); plt.ylabel(\"Scripts per 1,000\"); plt.xticks(rotation=45)\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / \"avg_scripts_per_1000_by_month_2015.png\", dpi=150); plt.close()\n",
    "\n",
    "# (b) Top 5 Antibiotic Classes in 2015 (Scripts/1,000)\n",
    "top5 = (\n",
    "    pbs.groupby(\"class_name\")[\"scripts_per_1000\"]\n",
    "       .sum()\n",
    "       .nlargest(5)\n",
    ")\n",
    "plt.figure()\n",
    "top5.plot(kind=\"bar\")\n",
    "plt.title(\"Top 5 Antibiotic Classes in 2015 (Scripts/1,000)\")\n",
    "plt.ylabel(\"Total Scripts per 1,000 in 2015\")\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / \"top5_antibiotic_classes_2015.png\", dpi=150); plt.close()\n",
    "\n",
    "# (c) Cumulative scripts per 1,000 (2015)\n",
    "cumulative = monthly_rate.cumsum()\n",
    "plt.figure()\n",
    "cumulative.plot(marker=\"o\")\n",
    "plt.title(\"Cumulative Antibiotic Scripts per 1,000 (2015)\")\n",
    "plt.xlabel(\"Month\"); plt.ylabel(\"Cumulative Scripts per 1,000\"); plt.xticks(rotation=45)\n",
    "plt.tight_layout(); plt.savefig(FIG_DIR / \"cumulative_scripts_per_1000_2015.png\", dpi=150); plt.close()\n",
    "\n",
    "print(\"\\nSaved cleaned CSVs in:\", OUT_DIR)\n",
    "print(\"Saved figures in:\", FIG_DIR)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
